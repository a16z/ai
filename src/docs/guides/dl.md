# Deep Learning


# What's New, What Isn't

If you know a bit of the history of AI, you might wonder what's really new about all this, in essence, you could very reasonably ask: "Haven't We Tried This Before?"

The answer is: not really.

While the fundamental ideas are generally the same, the scale at which we are using them has changed, and that has brought quantitatively different (and better) results, in large part because we can now test ideas we couldn't test before. Scale constraints also created a barrier to evolution. As cloud computing has made large-scale experiments possible, the techniques have also evolved and improved significantly. 

Prof Geoff Hinton (Google and University of Toronto) discussed why previous approaches failed [at this point in the talk](https://youtu.be/VhmE_UXDOGs?t=1330). The first two reasons he identifies have to do with scale ("Our labeled datasets were thousands of times too small ") and compute capabilities ("Our computers were millions of times too slow") which clearly don't speak only to the speed of processors but compute capacity in general (ie., including processor, memory, storage, networking).

# Why "Deep"

From [Wikipedia](https://en.wikipedia.org/wiki/Deep_learning):

> Deep learning (also known as deep structured learning, hierarchical learning or deep machine learning) is a branch of machine learning based on a set of algorithms that attempt to model high level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations
