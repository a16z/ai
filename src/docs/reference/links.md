# Videos, Tutorials, and Blogs

## Talks and Podcasts
* [AI And Deep Learning](http://a16z.com/2016/06/10/ai-deep-learning-machines/). From types of machine intelligence to a tour of algorithms, a16z Deal and Research team head Frank Chen walks us through the basics (and beyond) of AI and deep learning in this slide presentation.
* [a16z Podcast: The Product Edge in Machine Learning Startups](http://a16z.com/2017/03/17/machine-learning-startups-data-saas/). A lot of machine learning startups initially feel a bit of “impostor syndrome” around competing with big companies, because (the argument goes), those companies have all the data; surely we can’t beat that! Yet there are many ways startups can, and do, successfully compete with big companies. You can actually achieve great results in a lot of areas even with a relatively small data set, argue the guests on this podcast, if you build the right product on top of it.
* [When Humanity Meets AI](http://a16z.com/2016/06/29/feifei-li-a16z-professor-in-residence/). Andreessen Horowitz Distinguished Visiting Professor of Computer Science is Fei-Fei Li [who publishes under Li Fei-Fei], associate professor at Stanford University, argues we need to inject a stronger humanistic thinking element to design and develop algorithms and A.I. that can co-habitate with people and in social (including crowded) spaces.
* ["Large-Scale Deep Learning for Intelligent Computer Systems"](https://www.youtube.com/watch?v=QSaZGT4-6EY), Google Tech Talk with Jeff Dean at Campus Seoul, March 2016.
* Prof. Geoff Hinton [Neural Networks for Machine Learning](https://www.youtube.com/watch?v=cbeTc-Urqak&list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9), Coursera Lectures 2012.
* [Deep Learning and Understandability versus Software Engineering and Verification](https://www.youtube.com/watch?v=X769cyzBNVw), Peter Norvig, 2016.
* [Accelerating Understanding: Deep Learning, Intelligent Applications, and GPUs](https://www.youtube.com/watch?v=Qk4SqF9FT-M). The Institute for Scientific Computing Research (ISCR) sponsored this talk entitled "Deep Learning" on April 16, 2015, at the Lawrence Livermore National Laboratory. The talk was presented by Yann LeCun, director of AI research at Facebook and professor of data science, computer science, neural science and electrical engineering at NYU.
* [A DARPA Perspective on Artificial Intelligence](https://www.youtube.com/embed/-O01G3tSYpU). What's the ground truth on artificial intelligence (AI)? In this video, John Launchbury, the Director of DARPA's Information Innovation Office (I2O), attempts to demystify AI: what it can do, what it can't do, and where it is headed.

## Tutorials
* [Welch Labs introduction to neural networks](https://www.youtube.com/watch?v=bxe2T-V8XRs), a handful of 4-5 minute, well done videos
* [Google's Tensorflow tutorial](https://www.tensorflow.org/tutorials/)
* [Deep Learning for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/) a Google Codelab, originally developed by [Peter Warden](https://petewarden.com/2016/02/28/tensorflow-for-poets/)
* Google's 3-hour course [Learn TensorFlow and deep learning, without a Ph.D.](https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd)
* Stanford's [Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/)
* Watch technical talks from various past [Machine Learning Summer Schools](http://videolectures.net/site/search/?q=MLSS) or check out videos from the [2016 Deep Learning Summer School](http://videolectures.net/deeplearning2016_montreal/)


## MOOCs
* The classic: [Coursera Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning)
* [Udacity Introduction to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120)
* [Udacity Deep Learning by Google](https://www.udacity.com/course/deep-learning--ud730)
* "The trinity": Stanford class [CS221: Artificial Intelligence: Principles and Techniques by Percy Liang](http://web.stanford.edu/class/cs221/), Stanford class [CS224N Natural Language Processing with Deep Learning by Christopher Manning and Richard Socher](http://web.stanford.edu/class/cs224n/), [YouTube playlist](https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6), Stanford class [CS231N: Convolutional Neural Networks for Visual Recognition by Fei-Fei Li and Andrej Karapthy](http://cs231n.stanford.edu/), Github repo(http://cs231n.github.io/))
* [EdX Introduction to AI](https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0)
* Carnegie Mellon's [Introduction to Machine Learning](http://www.cs.cmu.edu/~mgormley/courses/10701-f16/), followed up by [Statistical Machine Learning](http://www.stat.cmu.edu/~larry/=sml/)
* MIT's [Artificial Intelligence with Patrick Henry Winston](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/)
* "The hard one": [Coursera's Neural Networks for Machine Learning with Geoff Hinton](https://www.coursera.org/learn/neural-networks)
* Class notes from [University of Iowa AI class on unsupervised learning](http://homepage.cs.uiowa.edu/~hzhang/c145/notes/18-unsupervised-6p.pdf)
* [List (and reviews) of top 5 list online classes](http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/), curated by Arthur Chan
* Fast.ai's 7-week [Practical Deep Learning](http://course.fast.ai/), taught by Jeremy Howard (past president of Kaggle, founder of Enlitic and fast.ai)

## Blogs and sites
* [Andrej Karpathy’s blog](http://karpathy.github.io/), check out [Unreasonable effectiveness of RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [KDNuggets: News, stories, job posts, data sets about machine learning (not just deep learning)](http://www.kdnuggets.com/)
* [Algobeans: great layman’s explanations of analytics concepts](https://algobeans.com/)
* [Arthur Chan’s blog](http://thegrandjanitor.com/)
* [Andrew Gibiansky’s occassionally updated blog posts explaining basic concepts](http://andrew.gibiansky.com/)
* [Christopher Olah's blog](http://colah.github.io/)
* [Edwin Chen's blog](http://blog.echen.me/)
* [Ujjwal Karn with occassional explanatory posts on data science](https://ujjwalkarn.me/)
* [Three Challenges for Artificial Intelligence in Medicine](https://blog.cardiogr.am/three-challenges-for-artificial-intelligence-in-medicine-dfb9993ae750) on the [Cardiogram blog](https://blog.cardiogr.am/)
* Robbie Allen's [curated list of AI and Machine Learning resources](https://unsupervisedmethods.com/my-curated-list-of-ai-and-machine-learning-resources-from-around-the-web-9a97823b8524)
* [Deep Learning for NLP Best Practices](http://ruder.io/deep-learning-nlp-best-practices/index.html)

## Mailing lists
* Azeem Azhar's [The Exponential View](https://www.getrevue.co/profile/azeem)
* Brian Petro's [AI Newsletter](http://angularjobs.us11.list-manage1.com/subscribe?u=57f6c28a9354055d3398d48e8&id=0aebe4c13c)
* CognitionX [AI News Briefing](http://cognitionx.com/#subscribe)
* David Lissmyr's [AI Weekly](http://aiweekly.co/)
* Denny Britz's [The Wild Week in AI](https://www.getrevue.co/profile/wildml)
* Jack Clark's [Import AI](http://us13.campaign-archive1.com/home/?u=67bd06787e84d73db24fb0aa5&id=6c9d98ff2c)
* O'Reilly [Artificial Intelligence Newsletter](http://www.oreilly.com/ai/newsletter.html?)
* O'Reilly [Data Newsletter](http://www.oreilly.com/data/newsletter.html)
* Rob May's [Inside AI](https://inside.com/technically-sentient), formerly known as Technically Sentient
* Sam DeBrule's [Machine Learnings, A Weekly Roundup of ML and AI News](http://subscribe.machinelearnings.co/)
* [The Visionary](http://www.thevisionary.com/), eyeing what's next in AI and computer vision
* Not all about AI/ML, but plenty of interesting content too: [a16z Newsletter](https://a16z.com/)
* Ditto: Benedict Evans' [Newsletter](http://ben-evans.com/newsletter/)


## Podcasts
* Matt Fogel's curated list of the [Top 10 Best AI, Data Science and Machine Learning Podcasts](https://medium.com/startup-grind/the-10-best-ai-data-science-and-machine-learning-podcasts-d7495cfb127c)
* nVidia's [The AI Podcast](https://blogs.nvidia.com/ai-podcast/)
* Katie Malone and Ben Jaffe host a fun, conversation-style podcast called [Linear Digressions](http://lineardigressions.com/) that explains how things work
* Sam Charrington's [This Week in Machine Learning & AI](https://twimlai.com/)
* We often talk about AI and ML on the [a16z podcast](https://a16z.com/category/artificial-intelligence/)


## Books

* The most popular textbook, [Artificial Intelligence, 3rd edition](http://aima.cs.berkeley.edu/) by Stuart Russell and Peter Norvig
* Michael Nielsen’s online book [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)
* [Draft of Andrew Ng’s upcoming book, Deep Learning Yearning](http://www.mlyearning.org/)
* [Textbook: Deep Learning](http://www.deeplearningbook.org/) by Ian Goodfellow and Yoshua Bengio and Aaron Courville
* [Reinforcement Learning and its Relationship to Supervised Learning](http://www-anw.cs.umass.edu/pubs/2004/barto_d_04.pdf)


## Other
* Check out Siraj Raval's [Artificial Intelligence Education YouTube channel](https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A). Here's a video on [AI generated music](https://www.youtube.com/watch?v=S_f2qV2_U00&list=PL2-dafEMk2A5-sn0Sgkw-4q-Lw0jiuQtu).
* Have fun at [Google's browser based AI Experiments site](https://aiexperiments.withgoogle.com/)
* Keep up to date with [Artificial Intelligence research papers at arXiv.org](https://arxiv.org/list/cs.AI/recent)
* Because there are too many papers to actually read, try @kaparthy's [arXiv Sanity browser](http://arxiv-sanity.com/)
* Check out the [latest articles about machine learning at Distill](http://distill.pub/)
* [Stanford University 100 Year Study on AI](https://ai100.stanford.edu/)
* [Summary of Schmidhumber’s long history and introduction by Annalyn Ng and Kenneth Soo](http://www.kdnuggets.com/2016/04/deep-learning-neural-networks-overview.html)
* [McKinsey study on AI and jobs](http://www.mckinsey.com/business-functions/digital-mckinsey/our-insights/where-machines-could-replace-humans-and-where-they-cant-yet)
* Dive into the [Machine Learning For Software Engineers rabbithole](https://github.com/ZuzooVn/machine-learning-for-software-engineers)
* Quora is continually adding Q&A around relevant topics such as [Artificial Intelligence](https://www.quora.com/topic/Artificial-Intelligence), [Machine Learning](https://www.quora.com/topic/Machine-Learning), and [Artificial Neural Networks](https://www.quora.com/topic/Artificial-Neural-Networks-ANNs).
* A curated list of how peopple are [using AI to do creative things](http://www.creativeai.net/) like write music, write stories, create paintings, and so on. 
* Along those lines, try @hardmaru's [Instragram feed full of deep learning generated sketches](https://www.instagram.com/hardmaru/). Fun!
* Fast AI's [Jupyter Notebook Enhancements, Tips and Tricks](http://forums.fast.ai/t/jupyter-notebook-enhancements-tips-and-tricks/17064)

## Referenced Links
* Steve Jobs's [bicycles for the minds video](https://youtu.be/ob_GX50Za6c?t=24)
* E.F. Codd's [original research paper proposing the relational database](https://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf) (1970)
* Oracle [published its first commercially available Oracle V2 database](https://docs.oracle.com/database/121/CNCPT/intro.htm#CNCPT88784) in 1979
* Harvard Business Review ["The Simple Economics of Machine Intelligence"](https://hbr.org/2016/11/the-simple-economics-of-machine-intelligence) published in November 2016
* Open source [MIT License](https://opensource.org/licenses/MIT)
* Jeff Bezos's AI history tl;dr in his [2016 letter to Amazon shareholders](https://www.sec.gov/Archives/edgar/data/1018724/000119312517120198/d373368dex991.htm)
* Jeff Dean's presentation on [Trends and Developments in Deep Learning Research](https://www.slideshare.net/AIFrontiers/jeff-dean-trends-and-developments-in-deep-learning-research)
* Jerry Kaplan defining artificial intelligence in his book [Artificial Intelligence: What Everyone Needs To Know](http://jerrykaplan.com/books/)
* [Stanford CoreNLP toolkit](http://stanfordnlp.github.io/CoreNLP/)
* Tools and frameworks include [scikit-learn](http://scikit-learn.org/stable/#), [Spark's MLlib](http://spark.apache.org/mllib/) (for a wide collection of machine learning techniques), [Tensorflow](https://www.tensorflow.org/), [Keras](https://keras.io/), [Caffe2](https://caffe2.ai/), [MXNet](http://mxnet.io/)(for deep learning models)
* [Paper outlining the tradeoffs between power, memory, accuracy, etc in deep neural networks](https://arxiv.org/pdf/1605.07678.pdf) by Canziani, Culurciello, and Paszke
* [Medium post describing a set of strategies for getting data](https://medium.com/@muellerfreitag/10-data-acquisition-strategies-for-startups-47166580ee48)
* [A tour of machine learning algorithms](http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)
* [The 10 Algorithms Machine Learning Engineers Need to Know](http://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html)
* Microsoft's developer documentation [How to choose machine learning algorithms for Microsoft Azure machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-algorithm-choice)
* [Stack Overflow answer to "When to choose which machine learning classifer?"](http://stackoverflow.com/questions/2595176/when-to-choose-which-machine-learning-classifier)
* Scikit-learn documentation: [Choosing the right estimator](http://scikit-learn.org/stable/tutorial/machine_learning_map/)
* Christopher Manning in his [introductory lecture for "CS Natural Language Processing with Deep Learning"](https://www.youtube.com/watch?v=OQQ-W_63UgQ&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6)
* Andrew L. Beam, [Deep Learning 101](http://beamandrew.github.io/deeplearning/2017/02/23/deep_learning_101_part1.html)
* Andrey Kruenkov, [A "Brief" of Neural Nets and Deep Learning](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/)
* Haohan Wang and Bhiksha Raj, [On the Origin of Deep Learning](https://arxiv.org/pdf/1702.07800.pdf) provide a good historical overview, explaining concepts including the math
* Jurgen Schmidhuber, [Deep Learning in Neural Networks: An Overview](https://arxiv.org/pdf/1404.7828.pdf) provides the most comprehensive and technically dense overview
* NVIDA's 2014 blog post [Accelerate Machine Learning with the cuDNN Deep Neural Network Library](http://devblogs.nvidia.com/parallelforall/accelerate-machine-learning-cudnn-deep-neural-network-library/)
* Watch Google legend Jeff Dean from the Google Brain team lecture on [Large-Scale Deep Learning for Intelligent Computer Systems](https://www.youtube.com/watch?v=4hqb3tdk01k)
* Read Michael Nielsen's excellent ebook and Website [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)
* [IEEE interview with UC Berkeley professor Michael Jordan from October 2014](http://spectrum.ieee.org/robotics/artificial-intelligence/machinelearning-maestro-michael-jordan-on-the-delusions-of-big-data-and-other-huge-engineering-efforts)
* [Wikipedia article on the types of artificial neural networks](https://en.wikipedia.org/wiki/Types_of_artificial_neural_networks)
* [Browser-based TensorFlow playground](http://playground.tensorflow.org/)
* [a16z AI Primer](http://a16z.com/2016/06/10/ai-deep-learning-machines)
* [Convolutional Neural Networks](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) introduced by LeCun, Bengio, Lottou, Haffer in 1998
* [ImageNet Large Scale Visual Recognition Challenge](http://www.image-net.org/challenges/LSVRC/) (ILSVRC)
* [A good beginner's guide on ConvNets](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/) written by a UCLA computer science undergrad named Adit Deshpande
* Andrej Karpathy's [class notes from Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/. Make sure to scroll down to see the cool animation that shows you what a convolution is.)
* Play with [Andrej Karpathy's ConvNetJS demo](http://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html) which trains a Convolutional Neural Network on the MNIST digits dataset (consisting of handwritten numerical digits) in the comfort of your own browser.
* [2013 paper by Matthew Zeiler and Rob Fergus](https://arxiv.org/abs/1311.2901) provides some visual examples that help you understand the intuition behind the architecture.
* There are many other types of neural networks. If you are interested in learning more, we suggest a visit to the Asimov's Institute [Neural Network Zoo](http://www.asimovinstitute.org/neural-network-zoo/)
* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), Christopher Olah's excellent overview article is a beautiful piece of explanatory writing and illustration.
* LSTM architecture introduction by [Hochreiter and Schmidhuber in 1997](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)
* Rohan Kapur's [Medium post on Recurrent Neural Networks & LSTMs](http://ayearofai.com/rohan-lenny-3-recurrent-neural-networks-10300100899b)
* [Top 15 Frameworks for Machine Learning Experts](http://www.kdnuggets.com/2016/04/top-15-frameworks-machine-learning-experts.html)
* The indefatigable Andrej Kaparthy posted a "Google Trends"-esque type analysis showing what's hot if you peek inside [28,303 machine learning research papers over the last 5 years](https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a1085a106)
* Ian Goodfellow et. al's 2014 [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) paper
* For the math-inclined, see [this Stanford tutorial which covers supervised and unsupervised learning](http://ufldl.stanford.edu/tutorial/) and includes code samples.
* Algobeans layman's explanation of [gradient descent in artificial neural networks](https://algobeans.com/2016/11/03/artificial-neural-networks-intro2/)
* Survey of unsupervised anomaly detection algorithms](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0152173)
* "YouTube cat finder" research that [kindled the general public's enthusiasm for AI](https://www.wired.com/2012/06/google-x-neural-network/) and the [accompanying paper by the Google Brain team and Stanford researchers Quoc Le and Andrew Ng](https://arxiv.org/abs/1112.6209)
* Xiaojin Zhu's [epic 135-slide tutorial on semi-supervised learning](http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf) and the [accompanying paper which surveys the literature back in 2008](http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf).
* DeepMind [published a paper in Nature](https://deepmind.com/blog/deep-reinforcement-learning/) describing a system that combines reinforcement learning with deep learning to learned to play a set of Atari video games, some with great success (like Breakout) and others terribly (like Montezuma's Revenge).
* The Nervana team (now at Intel) published an excellent explanatory blog post that walks through [deep reinforcement learning techniques](https://www.nervanasys.com/demystifying-deep-reinforcement-learning/) in detail.
* Richard Sutton and Andrew Barto [wrote the book on Reinforcement Learning](http://incompleteideas.net/sutton/book/the-book-1st.html). Check out the [draft of the 2nd edition](http://incompleteideas.net/sutton/book/the-book-2nd.html).
